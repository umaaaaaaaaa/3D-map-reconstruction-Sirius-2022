{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.15\n",
        "!apt install --allow-change-held-packages libcudnn7=7.4.1.5-1+cuda10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RqEL4l2mBkXJ",
        "outputId": "8689d76e-e161-4d9b-b288-99eb8d507b32"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.2+zzzcolab20220719082949.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "y\n",
            "n\n",
            "  Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 8.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.47.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 66.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.8.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=7d9d3894eb2f31480c7d75ecf6fe220847c6a7397820fc67bb0535ef497e3dfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn7-dev\n",
            "The following packages will be DOWNGRADED:\n",
            "  libcudnn7\n",
            "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 18 not upgraded.\n",
            "Need to get 149 MB of archives.\n",
            "After this operation, 485 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libcudnn7 7.4.1.5-1+cuda10.0 [149 MB]\n",
            "Fetched 149 MB in 3s (59.6 MB/s)\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Removing libcudnn7-dev (7.6.5.32-1+cuda10.1) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in auto mode\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn7 from 7.6.5.32-1+cuda10.1 to 7.4.1.5-1+cuda10.0\n",
            "(Reading database ... 155679 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn7_7.4.1.5-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libcudnn7 (7.4.1.5-1+cuda10.0) over (7.6.5.32-1+cuda10.1) ...\n",
            "Setting up libcudnn7 (7.4.1.5-1+cuda10.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nVVcCEmTe9KU",
        "outputId": "be61fc55-6498-4b56-d2d1-e159d6dbe4ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8d2919c1d33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow_version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_tensorflow_magics.py\u001b[0m in \u001b[0;36m_tensorflow_version\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m              \u001b[0mYour\u001b[0m \u001b[0mnotebook\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0mTensorflow\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m              \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mguide\u001b[0m \u001b[0mat\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmigrate\u001b[0m\u001b[0;31m#migrate-from-tensorflow-1x-to-tensorflow-2.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                        ))\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensorflow 1 is unsupported in Colab.\n\nYour notebook should be updated to use Tensorflow 2.\nSee the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2."
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401t1pswrBhR",
        "outputId": "19059420-5bfe-4148-991a-9d116b412254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtube-dl==2020.12.2\n",
            "  Downloading youtube_dl-2020.12.2-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 26.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2020.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-dl==2020.12.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S3Qy0tHT4QZ",
        "outputId": "678c567f-bed3-4df5-b2a1-89b8467fa279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLL_l9JZNci6",
        "outputId": "84cbc10c-e05e-47e2-d00d-6b476b225f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1puXG6vtc3PmvSidCZSBoM5t_EOMiE1qc\n",
            "To: /content/Krab-20220713T102128Z-001.zip\n",
            "100% 818k/818k [00:00<00:00, 134MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1puXG6vtc3PmvSidCZSBoM5t_EOMiE1qc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZGtLztwNoY-"
      },
      "outputs": [],
      "source": [
        "!unzip /content/Krab-20220713T102128Z-001.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prtugtjVc5oL",
        "outputId": "fe99b38d-b7fb-4ce1-9c30-b95ad8cd4d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting blend_modes\n",
            "  Downloading blend_modes-2.1.0.tar.gz (17 kB)\n",
            "Collecting pafy\n",
            "  Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Building wheels for collected packages: blend-modes\n",
            "  Building wheel for blend-modes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blend-modes: filename=blend_modes-2.1.0-py3-none-any.whl size=9555 sha256=3c7b9e087aadc38cb145b9e67533baaa19bbed474a04c6cde13e363d6f9e5af3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/58/99/5c5df7ca7a3fbd1819ca4e5e1c18680840a9d29f965347471c\n",
            "Successfully built blend-modes\n",
            "Installing collected packages: pafy, blend-modes\n",
            "Successfully installed blend-modes-2.1.0 pafy-0.5.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py<3.0.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install  numpy gast keras blend_modes pafy natsort\n",
        "!pip install 'h5py<3.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISltbRZHTLDN",
        "outputId": "269d1cd2-499e-4d49-cd2f-170d42e6f74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKC0ptb3epBU",
        "outputId": "9b400ae1-04d3-4542-c625-488a4cf7c48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fewshot-segmentation'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 90 (delta 41), reused 34 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n",
            "/content/fewshot-segmentation/source_code\n",
            "--2022-09-10 20:02:36--  https://github.com/OlegJakushkin/fewshot-segmentation/releases/download/1.1/VGG_b345_5_fewshot_DOGLSTM.h5\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/312966314/0242fd00-49cd-11eb-91d7-80dc7724cd1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220910%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220910T200236Z&X-Amz-Expires=300&X-Amz-Signature=0c120c9c44ab523144a7ee0f71a6601fa3e3460934db4ad8d965b5b3f5611263&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=312966314&response-content-disposition=attachment%3B%20filename%3DVGG_b345_5_fewshot_DOGLSTM.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-10 20:02:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/312966314/0242fd00-49cd-11eb-91d7-80dc7724cd1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220910%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220910T200236Z&X-Amz-Expires=300&X-Amz-Signature=0c120c9c44ab523144a7ee0f71a6601fa3e3460934db4ad8d965b5b3f5611263&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=312966314&response-content-disposition=attachment%3B%20filename%3DVGG_b345_5_fewshot_DOGLSTM.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146005920 (139M) [application/octet-stream]\n",
            "Saving to: ‘VGG_b345_5_fewshot_DOGLSTM.h5’\n",
            "\n",
            "VGG_b345_5_fewshot_ 100%[===================>] 139.24M  8.58MB/s    in 15s     \n",
            "\n",
            "2022-09-10 20:02:52 (9.48 MB/s) - ‘VGG_b345_5_fewshot_DOGLSTM.h5’ saved [146005920/146005920]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/OlegJakushkin/fewshot-segmentation \n",
        "%cd /content/fewshot-segmentation/source_code\n",
        "!wget https://github.com/OlegJakushkin/fewshot-segmentation/releases/download/1.1/VGG_b345_5_fewshot_DOGLSTM.h5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQgSfBCwVGUT",
        "outputId": "3f024b72-34f2-4c3d-d1fb-be83d7c1a157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXnZ7MGORGbu",
        "outputId": "1262042e-2a84-4652-b4b6-6f6b24a37834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Hierarchical-Localization\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/Hierarchical-Localization\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision>=0.3 in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (4.6.0.66)\n",
            "Requirement already satisfied: tqdm>=4.36.0 in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (1.7.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (2.10.0)\n",
            "Collecting pycolmap>=0.3.0\n",
            "  Downloading pycolmap-0.3.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 17.7 MB/s \n",
            "\u001b[?25hCollecting kornia>=0.6.4\n",
            "  Downloading kornia-0.6.7-py2.py3-none-any.whl (565 kB)\n",
            "\u001b[K     |████████████████████████████████| 565 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from hloc==1.3) (4.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia>=0.6.4->hloc==1.3) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->hloc==1.3) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3->hloc==1.3) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3->hloc==1.3) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->hloc==1.3) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown->hloc==1.3) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown->hloc==1.3) (4.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->hloc==1.3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->hloc==1.3) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->hloc==1.3) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->hloc==1.3) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->hloc==1.3) (8.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.3->hloc==1.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.3->hloc==1.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.3->hloc==1.3) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.3->hloc==1.3) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.3->hloc==1.3) (1.7.1)\n",
            "Installing collected packages: pycolmap, kornia, hloc\n",
            "  Running setup.py develop for hloc\n",
            "Successfully installed hloc-1.3 kornia-0.6.7 pycolmap-0.3.0\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 105 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!git clone --quiet --recursive https://github.com/cvg/Hierarchical-Localization/\n",
        "%cd /content/Hierarchical-Localization\n",
        "!pip install -e .\n",
        "!pip install --upgrade --quiet plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kCjB5xOlVT8p"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLWgjEeDVqVl",
        "outputId": "f79e0665-cebb-45f3-a63c-567f2f5f9256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Hierarchical-Localization\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Hierarchical-Localization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a74D5fMuV5R-",
        "outputId": "68f215d8-1a91-4534-f1db-5ec398a2486e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Hierarchical-Localization\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eEIAUJj3VQG7"
      },
      "outputs": [],
      "source": [
        "\n",
        "images = Path('/content/Hierarchical-Localization/bottom')#Path('/content/drive/MyDrive/ColabNotebooks/Sirius_2022/sea-bottom-data-2')\n",
        "outputs = Path('outputs/demo/')\n",
        "!rm -rf $outputs\n",
        "sfm_pairs = outputs / 'pairs-sfm.txt'\n",
        "loc_pairs = outputs / 'pairs-loc.txt'\n",
        "sfm_dir = outputs / 'sfm'\n",
        "features = outputs / 'features.h5'\n",
        "matches = outputs / 'matches.h5'\n",
        "\n",
        "# feature_conf = extract_features.confs['superpoint_aachen']\n",
        "# matcher_conf = match_features.confs['superglue']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8bqN77jJRKnm"
      },
      "outputs": [],
      "source": [
        "from hloc.utils import read_write_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4yw5tl6wRRxT"
      },
      "outputs": [],
      "source": [
        "imges = read_write_model.read_images_binary(\"/content/images.bin\")\n",
        "pnts = read_write_model.read_points3D_binary(\"/content/points3D.bin\")\n",
        "cams = read_write_model.read_cameras_binary(\"/content/cameras.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n486-Z8vx21I",
        "outputId": "2bf65608-259b-4f39-ca23-158cd529b74e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Hierarchical-Localization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zen7hbwSNfOx",
        "outputId": "8aa5f6af-0d9a-474b-ea21-f66d143cfe45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fewshot-segmentation/source_code\n"
          ]
        }
      ],
      "source": [
        "%cd /content/fewshot-segmentation/source_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wj8l7rRezJT"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import time\n",
        "import model as  Mo\n",
        "import matplotlib.pyplot as plt\n",
        "import utilz as U\n",
        "import numpy as np\n",
        "from parser_utils import get_parser\n",
        "import pickle\n",
        "import random \n",
        "import cv2\n",
        "import copy\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from blend_modes import *\n",
        "import pafy\n",
        "from natsort import natsorted, ns\n",
        "import shutil\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "## Get AI options\n",
        "options =type('Expando', (object,), {})()\n",
        "options.img_h = 224\n",
        "options.img_w = 224\n",
        "options.s_h = 56\n",
        "options.s_w = 56\n",
        "options.kshot = 5\n",
        "options.nway = 5\n",
        "options.learning_rate = 0.0001\n",
        "\n",
        "#we are ready for 5 class 5 shot queries.\n",
        "#each folder in folder_with_sample_folders must have \n",
        "#up to 5 jpg color images \n",
        "#with a black and white mask png file per image\n",
        "#query must be a colored image\n",
        "folder_with_sample_folders = \"/content/Krab/\"\n",
        "\n",
        "model_weights_path = './VGG_b345_5_fewshot_DOGLSTM.h5'\n",
        "\n",
        "\n",
        "def data(opt, folder_with_sample_folders):\n",
        "    support = np.zeros([opt.nway, opt.kshot, opt.img_h, opt.img_w, 3], dtype = np.float32)\n",
        "    smasks  = np.zeros([opt.nway, opt.kshot, opt.s_h, opt.s_w,        1], dtype = np.float32)\n",
        "\n",
        "    setX = os.listdir(folder_with_sample_folders)\n",
        "    setX = natsorted(setX, alg=ns.PATH | ns.IGNORECASE)\n",
        "    print(opt.nway)\n",
        "    for idx in range(opt.nway):\n",
        "        print(idx)\n",
        "        for idy in range(0, opt.kshot): # For support set \n",
        "            print(idy)\n",
        "            s_img = ''\n",
        "            if os.path.isfile(folder_with_sample_folders + setX[idx] + '/' + str(idy+1) + '.jpg' ):\n",
        "              s_img = cv2.imread(folder_with_sample_folders + setX[idx] + '/' + str(idy+1) + '.jpg' ) \n",
        "            elif os.path.isfile(folder_with_sample_folders + setX[idx] + '/' + str(idy+1) + '.jpeg' ):\n",
        "              s_img = cv2.imread(folder_with_sample_folders + setX[idx] + '/' + str(idy+1) + '.jpeg' )\n",
        "            else:\n",
        "              continue\n",
        "            s_msk = cv2.imread(folder_with_sample_folders + setX[idx] + '/' + str(idy+1) + '.png' )\n",
        "            print(folder_with_sample_folders + setX[idx] + '/' + str(idy+1) + '.png' )\n",
        "            s_img = cv2.resize(s_img,(opt.img_h, opt.img_w))\n",
        "            s_msk = s_msk /255\n",
        "            s_msk = cv2.resize(s_msk,(opt.s_h, opt.s_w))\n",
        "\n",
        "            s_msk = np.where(s_msk > 0.5, 1., 0.)\n",
        "\n",
        "            support[idx, idy] = s_img\n",
        "            smasks[idx, idy]  = s_msk[:, :, 0:1] \n",
        "\n",
        "    support = support /255.\n",
        "    return support, smasks   \n",
        "\n",
        "\n",
        "def draw_bounding(frame, contours, hierarchy, big_array):\n",
        "  height, width, _ = frame.shape\n",
        "  min_x, min_y = width, height\n",
        "  max_x = max_y = 0\n",
        "  # computes the bounding box for the contour, and draws it on the frame,\n",
        "  for contour in contours:\n",
        "      (x,y,w,h) = cv2.boundingRect(contour)\n",
        "      min_x, max_x = min(x, min_x), max(x+w, max_x)\n",
        "      min_y, max_y = min(y, min_y), max(y+h, max_y)\n",
        "      frame = cv2.rectangle(frame, (x,y), (x+w,y+h), (255, 0, 0), 2)\n",
        "      id_3D = [i for i,k in enumerate(imges[1].point3D_ids) if k!=-1]\n",
        "      bnd_point = np.array([x,y])\n",
        "      keypoints = imges[1].xys\n",
        "      #ищем ближайшую точку\n",
        "      distances = np.linalg.norm(keypoints-bnd_point, axis=1)\n",
        "      min_index = np.argmin(distances)\n",
        "      nearest_point = keypoints[min_index]\n",
        "      frame = cv2.circle(frame, tuple([int(nearest_point[0]), int(nearest_point[1])]), radius = 5, color = (0, 255, 0),thickness = 2)\n",
        "      big_array = np.vstack((big_array, np.array(nearest_point)))\n",
        "\n",
        "      # проверить есть ли индекс в 3д точках\n",
        "\n",
        "      index_3D = imges[1].point3D_ids[min_index]\n",
        "\n",
        "      if index_3D != -1:\n",
        "        print(pnts[index_3D]).xyz\n",
        "      else:\n",
        "        print('None')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # for num, point in enumerate(imges[1].xys[id_3D]):\n",
        "      #   result = cv2.pointPolygonTest(contour, (point[0], point[1]), False)\n",
        "      #   if result == 1:\n",
        "      #     print(num)\n",
        "      #     print(id_3D[num])\n",
        "      #     print(point)\n",
        "      #     # print(point_3D)\n",
        "      #     point_3D = pnts[id_3D[num]].xyz\n",
        "          \n",
        "          \n",
        "  #         temp_ar = np.array([x,y,x+w,y+h,point_3D[0],point_3D[1], point_3D[2]])\n",
        "  #         \n",
        "  # print(big_array)\n",
        "  return frame\n",
        "\n",
        "\n",
        "\n",
        "def read_video(opt, big_array): \n",
        "    print(\"model loading....\")\n",
        "    model = Mo.my_model(encoder = 'VGG_b345', input_size = (options.img_h, options.img_w, 3), k_shot = options.kshot, learning_rate = options.learning_rate)\n",
        "    model.summary()\n",
        "    model.load_weights(model_weights_path)\n",
        "    overall_miou = 0.0\n",
        "    \n",
        "    ## Get an episode for test \n",
        "    support, smask = data(opt, folder_with_sample_folders)\n",
        "    print(\"model initiated\")\n",
        "\n",
        "    Ss_mask = None\n",
        "    OSs_mask = None\n",
        "    print(\"Started reading video file\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    frame = cv2.imread('/content/img0001.jpg')\n",
        "    print(frame)\n",
        "    frame = cv2.resize(frame, (224*6,224*3))\n",
        "\n",
        "    imgheight=frame.shape[0]\n",
        "    imgwidth=frame.shape[1]\n",
        "    y1 = 0\n",
        "    imgheight=frame.shape[0]\n",
        "    imgwidth=frame.shape[1]\n",
        "    K=int(imgheight / 224)\n",
        "    L=int(imgwidth / 224)\n",
        "    M = imgheight//K\n",
        "    N = imgwidth//L\n",
        "    blocks1=[]\n",
        "    blocks2=[]\n",
        "    blocks3=[]\n",
        "    blocks4=[]\n",
        "    blocks5=[]\n",
        "    query   = np.zeros([opt.nway, opt.img_h, opt.img_w, 3], dtype = np.float32)   \n",
        "    \n",
        "\n",
        "    for y in range(0,imgheight,M):\n",
        "        for x in range(0, imgwidth, N):\n",
        "            y1 = y + M\n",
        "            x1 = x + N\n",
        "            tiles = frame[y:y+M,x:x+N]\n",
        "            for idx in range(opt.nway):\n",
        "                query[idx] = tiles.copy()\n",
        "            query   = query   /255\n",
        "            Ss_mask = model.predict([support, smask, query])\n",
        "            print('predicted')\n",
        "            Es_mask = Ss_mask\n",
        "            Es_mask = np.where(Es_mask > 0.5, 1 , 0.)\n",
        "            Es_mask = Es_mask * 255\n",
        "            #o1 is crab\n",
        "\n",
        "            \n",
        "            \n",
        "            def store(O, blocks, tiles, big_array):\n",
        "                O = cv2.resize(O, (options.img_h, options.img_w)).astype(numpy.uint8)\n",
        "                ret, thresh = cv2.threshold(O, 1, 255, cv2.THRESH_BINARY)\n",
        "                contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                O = cv2.cvtColor(O, cv2.COLOR_GRAY2BGRA)\n",
        "                O[:, :, 0] = 0\n",
        "                O[:, :, 2] = 0\n",
        "                O[:, :, 3] = 255\n",
        "                tiles = cv2.cvtColor(tiles, cv2.COLOR_BGR2BGRA)\n",
        "                s = O.astype(float) \n",
        "                opacity = 0.6\n",
        "                tiles = tiles.astype(float)\n",
        "                blended = soft_light(tiles, s, opacity).astype(numpy.uint8)\n",
        "                blended = cv2.cvtColor(blended, cv2.COLOR_BGRA2BGR)\n",
        "                blended = cv2.drawContours(blended, contours, -1, (240, 240, 255), 2)\n",
        "\n",
        "                \n",
        "                blended = draw_bounding(blended, contours, hierarchy,big_array)\n",
        "                blocks.append(blended.copy())\n",
        "            \n",
        "\n",
        "            O1 = Es_mask[0]\n",
        "            store(O1, blocks1, tiles, big_array)\n",
        "            \"\"\"\n",
        "            O2 = Es_mask[1]\n",
        "            store(O2, blocks2, tiles)\n",
        "            \n",
        "            O3 = Es_mask[2]\n",
        "            store(O3, blocks3, tiles)\n",
        "\n",
        "            O4 = Es_mask[3]\n",
        "            store(O4, blocks4, tiles)\n",
        "\n",
        "            O5 = Es_mask[4]\n",
        "            store(O5, blocks5, tiles)\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "    def draw(blocks, frame_src):\n",
        "        I = 0\n",
        "        frame = frame_src.copy()\n",
        "        for y in range(0,imgheight,M):\n",
        "            for x in range(0, imgwidth, N):\n",
        "                frame[y:y+M,x:x+N] = blocks[I]\n",
        "                I = I+1\n",
        "        return frame\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    crabs = draw(blocks1, frame)\n",
        "    cv2_imshow(frame)\n",
        "    cv2_imshow(crabs)\n",
        "\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    \"\"\"\n",
        "    calamari = draw(blocks2, frame)\n",
        "    print(\"calamari\")\n",
        "    cv2_imshow(calamari)\n",
        "\n",
        "    swarm_fish = draw(blocks3, frame)\n",
        "    print(\"swarm_fish\")\n",
        "    cv2_imshow(swarm_fish)\n",
        "\n",
        "    omar = draw(blocks4, frame)\n",
        "    print(\"omar\")\n",
        "    cv2_imshow(omar)\n",
        "\n",
        "    spider_crab = draw(blocks5, frame)\n",
        "    print(\"spider_crab\")\n",
        "    cv2_imshow(spider_crab)\n",
        "    \"\"\"\n",
        "    cv2.imwrite(os.path.join('/content/' , 'detected_crabs.png'), crabs)\n",
        "    print(\"saving results\")\n",
        "\n",
        "    print(\"done\")\n",
        "\n",
        "big_array = np.array([0,0])  \n",
        "read_video(options,big_array) \n",
        "print(big_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPQJ1VvjKhWM"
      },
      "outputs": [],
      "source": [
        "imag = cv2.imread('/content/detected_crabs.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFcjyTQ4HuDt"
      },
      "outputs": [],
      "source": [
        "image = cv2.circle(imag, tuple([128 ,  53]), radius = 5, color = (255, 0, 0),thickness = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv7gjuPKLn9A"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}